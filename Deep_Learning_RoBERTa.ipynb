{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82238d01f6c448e4bb587960f39f1723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33566efc1cf04610b3ac10d53c9b7dd3",
              "IPY_MODEL_fd7ea3ed4a684bc99b276349169e8c07",
              "IPY_MODEL_eb4aec36fcfd4d399ff3b2ef0ac527d2"
            ],
            "layout": "IPY_MODEL_7fe590c7b33a4db0976c62dc8d28864c"
          }
        },
        "33566efc1cf04610b3ac10d53c9b7dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea76dbc85f64663b9de5186ee9905ae",
            "placeholder": "​",
            "style": "IPY_MODEL_631695e030944160bbfebaaa192b41e8",
            "value": "100%"
          }
        },
        "fd7ea3ed4a684bc99b276349169e8c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd8febfe697b430e9970bbee229a46b1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12c4754853294ae1a4b66856be640917",
            "value": 5
          }
        },
        "eb4aec36fcfd4d399ff3b2ef0ac527d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a81a5ec252f747bcbcdb4e5d3fe9f74c",
            "placeholder": "​",
            "style": "IPY_MODEL_2537956ee5824bd98b0408f8a51a9c8b",
            "value": " 5/5 [1:12:18&lt;00:00, 867.22s/it]"
          }
        },
        "7fe590c7b33a4db0976c62dc8d28864c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea76dbc85f64663b9de5186ee9905ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631695e030944160bbfebaaa192b41e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd8febfe697b430e9970bbee229a46b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c4754853294ae1a4b66856be640917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a81a5ec252f747bcbcdb4e5d3fe9f74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2537956ee5824bd98b0408f8a51a9c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mining of large datasets - Project**\n",
        "## Deep Learning approach using RoBERTa to classify the SST-5 dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "ESYom5NrsWY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install required packages (if needed)\n",
        "! pip install transformers\n",
        "! pip install imbalanced-learn\n",
        "! pip install timebudget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY1VAxsrtj5e",
        "outputId": "29cb38f9-7837-4d03-ac81-9ab31a8d01eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 26.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timebudget\n",
            "  Downloading timebudget-0.7.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: timebudget\n",
            "Successfully installed timebudget-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "WCD9r7U-ayU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sBHBH_88sAbp"
      },
      "outputs": [],
      "source": [
        "#Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "from timebudget import timebudget\n",
        "timebudget.report_atexit()  # Generate report when the program exits\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets (train, validation and testing)\n",
        "\n",
        "We have included a zip file containing the datasets."
      ],
      "metadata": {
        "id": "OB03mvw7a8Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load training, validation and testing datasets\n",
        "train_dataset = pd.read_csv('./train.txt', sep=\"\\t\", header=None, names=[\"label\", \"data\"])\n",
        "validation_dataset = pd.read_csv('./dev.txt', sep=\"\\t\", header=None, names=[\"label\", \"data\"])\n",
        "test_dataset = pd.read_csv('./test.txt', sep=\"\\t\", header=None, names=[\"label\", \"data\"])"
      ],
      "metadata": {
        "id": "ODnchrohsGda"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore distribution of datasets\n",
        "\n",
        "fig, ax = plt.subplots(3, figsize=(5,10))\n",
        "fig.suptitle('Distribution of datasets')\n",
        "\n",
        "#Training data\n",
        "ax[0] = train_dataset['label'].value_counts(sort=False).plot(kind='barh', ax=ax[0])\n",
        "ax[0].set_xlabel('Number of Samples (Training)')\n",
        "ax[0].set_ylabel('Label')\n",
        "\n",
        "for i, v in enumerate(train_dataset['label'].value_counts(sort=False)):\n",
        "    ax[0].text(v + 3, i + .25, str(v), fontweight='bold')\n",
        "\n",
        "# #Validation data\n",
        "ax[1] = validation_dataset['label'].value_counts(sort=False).plot(kind='barh', ax=ax[1])\n",
        "ax[1].set_xlabel('Number of Samples (Validation)')\n",
        "ax[1].set_ylabel('Label')\n",
        "\n",
        "for i, v in enumerate(validation_dataset['label'].value_counts(sort=False)):\n",
        "    ax[1].text(v + 3, i + .25, str(v), fontweight='bold')\n",
        "\n",
        "# #Testing data\n",
        "ax[2] = test_dataset['label'].value_counts(sort=False).plot(kind='barh', ax=ax[2])\n",
        "ax[2].set_xlabel('Number of Samples (Testing)')\n",
        "ax[2].set_ylabel('Label')\n",
        "\n",
        "for i, v in enumerate(test_dataset['label'].value_counts(sort=False)):\n",
        "    ax[2].text(v + 3, i + .25, str(v), fontweight='bold')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "uzcMxNR6f8dD",
        "outputId": "0822faf4-a2ae-450a-e578-1d010dbf434d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x720 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balancing datasets\n",
        "\n",
        "To deal with unbalanced data we will oversample and undersample the datasets"
      ],
      "metadata": {
        "id": "wN5SVLKcckyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Oversampling minority classes\n",
        "c0 = train_dataset[train_dataset['label'] == 1]\n",
        "c1 = train_dataset[train_dataset['label'] == 2]\n",
        "c2 = train_dataset[train_dataset['label'] == 3]\n",
        "c3 = train_dataset[train_dataset['label'] == 4]\n",
        "c4 = train_dataset[train_dataset['label'] == 5]\n",
        "\n",
        "max_count = train_dataset.label.value_counts().max()\n",
        "\n",
        "over_c0 = c0.sample(max_count, replace='True')\n",
        "over_c1 = c1.sample(max_count, replace='True')\n",
        "over_c2 = c2.sample(max_count, replace='True')\n",
        "over_c4 = c4.sample(max_count, replace='True')\n",
        "\n",
        "oversampled_train_dataset = pd.concat([over_c0,over_c1, over_c2, c3, over_c4], axis=0)\n",
        "\n",
        "#Undersampling majority classes\n",
        "min_count = train_dataset.label.value_counts().min()\n",
        "under_c1 = c1.sample(min_count)\n",
        "under_c2 = c2.sample(min_count)\n",
        "under_c3 = c3.sample(min_count)\n",
        "under_c4 = c4.sample(min_count)\n",
        "\n",
        "undersampled_train_dataset = pd.concat([c0,under_c1, under_c2, under_c3, under_c4], axis=0)\n",
        "\n",
        "print('Oversampled dataset: \\n', oversampled_train_dataset.label.value_counts())\n",
        "\n",
        "print('Undersampled dataset: \\n', undersampled_train_dataset.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij9pZUBocpuk",
        "outputId": "7f2909ea-9387-4ca1-9ac3-e03887560212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oversampled dataset: \n",
            " 1    2322\n",
            "2    2322\n",
            "3    2322\n",
            "4    2322\n",
            "5    2322\n",
            "Name: label, dtype: int64\n",
            "Undersampled dataset: \n",
            " 1    1092\n",
            "2    1092\n",
            "3    1092\n",
            "4    1092\n",
            "5    1092\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define architecture of RoBERTa model\n",
        "\n",
        "class ROBERTAClassifier(torch.nn.Module):\n",
        "    def __init__(self, n_classes, dropout_rate=0.3):\n",
        "        super(ROBERTAClassifier, self).__init__()\n",
        "        \n",
        "        # config = RobertaConfig.from_pretrained('roberta-base')\n",
        "        # config.num_labels = n_classes\n",
        "        # self.roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)\n",
        "\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l1 = torch.nn.Linear(768, 64)\n",
        "        self.bn1 = torch.nn.LayerNorm(64)\n",
        "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l2 = torch.nn.Linear(64, n_classes)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        # x = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0]\n",
        "\n",
        "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "\n",
        "        x = self.d1(x)\n",
        "        x = self.l1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.nn.Tanh()(x)\n",
        "        x = self.d2(x)\n",
        "\n",
        "        x = self.l2(x)\n",
        "        # x = F.softmax(self.l2(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WLpwcWP_waNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the number of classes\n",
        "n_classes = train_dataset['label'].nunique()\n",
        "print('N classes: ', n_classes)\n",
        "\n",
        "model = ROBERTAClassifier(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGK2aZL2wiYm",
        "outputId": "7fd0c169-8b64-403e-9a2a-63e3ccd7ed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N classes:  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "id": "i9fYTGaSwlkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features(review, zero_pad = False, max_seq_length = 512):\n",
        "    \n",
        "    enc_text = tokenizer.encode_plus(text=review, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n",
        "    return enc_text"
      ],
      "metadata": {
        "id": "GQPFvPTQ9PIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_review = train_dataset.loc[0]['data']\n",
        "print(example_review)\n",
        "enc_example = prepare_features(example_review)\n",
        "print(enc_example)\n",
        "print(len(enc_example['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdhcORzd98B7",
        "outputId": "777801c5-efb5-4a7b-ffe2-d74a46834e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
            "{'input_ids': [0, 133, 2751, 16, 19083, 7, 28, 5, 733, 620, 9348, 128, 29, 92, 45518, 38650, 12801, 8, 14, 37, 128, 29, 164, 7, 146, 10, 17158, 190, 2388, 87, 11816, 28797, 2156, 5363, 12, 11428, 5247, 3415, 8234, 1794, 50, 5031, 1608, 9487, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Class to prepare X and Y data\n",
        "class Format_Data(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        review = self.data['data'].iloc[index]\n",
        "\n",
        "        X = prepare_features(review)\n",
        "\n",
        "        #Transform current classes [1,2,3,4,5] to [0,1,2,3,4]\n",
        "        y = self.data['label'].iloc[index] - 1\n",
        "        \n",
        "        return np.array(X['input_ids']), np.array(X['attention_mask']), np.array(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "28XzPYZU-buk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = Format_Data(train_dataset)\n",
        "# oversampled_training_set = Format_Data(oversampled_train_dataset)\n",
        "# undersampled_training_set = Format_Data(undersampled_train_dataset)\n",
        "\n",
        "validation_set = Format_Data(validation_dataset)\n"
      ],
      "metadata": {
        "id": "IObL842O_nY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_set = Format_Data(test_dataset)"
      ],
      "metadata": {
        "id": "qFpwg3eAeniX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataloaders Parameters\n",
        "params = {'batch_size': 8}\n"
      ],
      "metadata": {
        "id": "PFPcIAYyADs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training using undersampled/oversampled/original dataset"
      ],
      "metadata": {
        "id": "JhedR1xqgiGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# u_training_loader = DataLoader(undersampled_training_set, **params)\n",
        "# o_training_loader = DataLoader(oversampled_training_set, **params)\n",
        "training_loader = DataLoader(training_set, **params)\n",
        "validation_loader = DataLoader(validation_set, **params)\n"
      ],
      "metadata": {
        "id": "Meg0zQmpeqjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_loader = DataLoader(testing_set, **params)"
      ],
      "metadata": {
        "id": "ockteNPMesvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.AdamW(params=model.parameters(), betas=(0.9, 0.98), lr=learning_rate)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is AVAILABLE!🤘🙌💪\")\n",
        "    model = model.cuda()"
      ],
      "metadata": {
        "id": "4eXvG6IaAKr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d74b8cd-93f2-4be1-e376-4f74cb6c9d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is AVAILABLE!🤘🙌💪\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "@timebudget\n",
        "def train(model, epochs, training_loader_):\n",
        "  best_accuracy = 0.0 \n",
        "  max_epochs = epochs\n",
        "  for epoch in tqdm_notebook(range(max_epochs)):\n",
        "\n",
        "      train_loss = 0.0\n",
        "      model.train()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for i, (ids, attention_mask, labels) in enumerate(training_loader_):\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          if torch.cuda.is_available():\n",
        "              ids = ids.cuda()\n",
        "              attention_mask = attention_mask.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "          output = model.forward(ids, attention_mask=attention_mask)\n",
        "\n",
        "          loss = loss_function(output, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item()\n",
        "\n",
        "          #Output acc every 100\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          accuracy = 100.00 * correct / total\n",
        "\n",
        "          if i%100 == 0:\n",
        "              print('Iteration: {}. Loss: {}. Training Accuracy: {}.%'.format(i, loss.item(), accuracy))\n",
        "\n",
        "      #Calculate training accuracy and loss\n",
        "      final_t_accuracy = 100.00 * correct / total\n",
        "      avg_t_loss = train_loss / len(training_loader_)\n",
        "        \n",
        "      #Validation loop\n",
        "      valid_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          model.eval()\n",
        "          for i, (ids, attention_mask, labels) in enumerate(validation_loader):\n",
        "\n",
        "              if torch.cuda.is_available():\n",
        "                  ids = ids.cuda()\n",
        "                  attention_mask = attention_mask.cuda()\n",
        "                  labels = labels.cuda()\n",
        "          \n",
        "              output = model.forward(ids, attention_mask=attention_mask)\n",
        "              loss = loss_function(output, labels)\n",
        "              valid_loss += loss.item()\n",
        "\n",
        "              _, predicted = torch.max(output, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              accuracy = 100.00 * correct / total\n",
        "\n",
        "              if i%100 == 0:\n",
        "                  print('Iteration: {}. Loss: {}. Validation Accuracy: {}.%'.format(i, loss.item(), accuracy))\n",
        "\n",
        "      #Calculate validation accuracy and loss\n",
        "      final_v_accuracy = 100.00 * correct / total\n",
        "      avg_v_loss = valid_loss / len(validation_loader)\n",
        "\n",
        "      #Report results per epoch\n",
        "      print(f'Epoch {epoch} \\t Training Loss: {avg_t_loss} \\t Training Accuracy: {final_t_accuracy} \\t Validation Loss: {avg_v_loss} \\t Validation Accuracy: {final_v_accuracy}')\n",
        "\n",
        "      # Save the model if the accuracy is the best \n",
        "      if final_v_accuracy > best_accuracy: \n",
        "            print(f'Accuracy increased({best_accuracy:.6f}--->{final_v_accuracy:.6f}) \\t Saving The Model')\n",
        "            best_accuracy = final_v_accuracy\n",
        "            torch.save(model.state_dict(), './mymodel.pt')                    \n",
        "  \n",
        "  return \"Training finished!\""
      ],
      "metadata": {
        "id": "jTIUuNsZAwS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, 5, training_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "82238d01f6c448e4bb587960f39f1723",
            "33566efc1cf04610b3ac10d53c9b7dd3",
            "fd7ea3ed4a684bc99b276349169e8c07",
            "eb4aec36fcfd4d399ff3b2ef0ac527d2",
            "7fe590c7b33a4db0976c62dc8d28864c",
            "6ea76dbc85f64663b9de5186ee9905ae",
            "631695e030944160bbfebaaa192b41e8",
            "cd8febfe697b430e9970bbee229a46b1",
            "12c4754853294ae1a4b66856be640917",
            "a81a5ec252f747bcbcdb4e5d3fe9f74c",
            "2537956ee5824bd98b0408f8a51a9c8b"
          ]
        },
        "id": "ku2uAUAgGamV",
        "outputId": "77e2cfcd-1522-48b3-e59f-c882c8b2805c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  import sys\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82238d01f6c448e4bb587960f39f1723",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0. Loss: 1.9123878479003906. Training Accuracy: 0.0.%\n",
            "Iteration: 100. Loss: 1.4801982641220093. Training Accuracy: 42.82178217821782.%\n",
            "Iteration: 200. Loss: 1.0363661050796509. Training Accuracy: 45.646766169154226.%\n",
            "Iteration: 300. Loss: 0.8117481470108032. Training Accuracy: 47.79900332225914.%\n",
            "Iteration: 400. Loss: 1.1208134889602661. Training Accuracy: 49.781795511221944.%\n",
            "Iteration: 500. Loss: 1.4582126140594482. Training Accuracy: 50.424151696606785.%\n",
            "Iteration: 600. Loss: 1.137970209121704. Training Accuracy: 48.48169717138103.%\n",
            "Iteration: 700. Loss: 1.7825311422348022. Training Accuracy: 48.44864479315264.%\n",
            "Iteration: 800. Loss: 1.1688129901885986. Training Accuracy: 48.36142322097378.%\n",
            "Iteration: 900. Loss: 1.3552838563919067. Training Accuracy: 48.46004439511654.%\n",
            "Iteration: 1000. Loss: 1.305487036705017. Training Accuracy: 48.57642357642358.%\n",
            "Iteration: 0. Loss: 1.6790359020233154. Validation Accuracy: 25.0.%\n",
            "Iteration: 100. Loss: 1.0806810855865479. Validation Accuracy: 38.242574257425744.%\n",
            "Epoch 0 \t Training Loss: 1.1728694087891989 \t Training Accuracy: 48.46676029962547 \t Validation Loss: 1.3268241173979165 \t Validation Accuracy: 39.782016348773844\n",
            "Accuracy increased(0.000000--->39.782016) \t Saving The Model\n",
            "Iteration: 0. Loss: 1.4137310981750488. Training Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 0.9568563103675842. Training Accuracy: 58.415841584158414.%\n",
            "Iteration: 200. Loss: 0.8020365834236145. Training Accuracy: 57.77363184079602.%\n",
            "Iteration: 300. Loss: 0.9872041344642639. Training Accuracy: 58.43023255813954.%\n",
            "Iteration: 400. Loss: 0.8540629744529724. Training Accuracy: 59.03990024937656.%\n",
            "Iteration: 500. Loss: 1.2937661409378052. Training Accuracy: 59.231536926147704.%\n",
            "Iteration: 600. Loss: 1.2098586559295654. Training Accuracy: 57.009151414309486.%\n",
            "Iteration: 700. Loss: 1.4137415885925293. Training Accuracy: 56.65121255349501.%\n",
            "Iteration: 800. Loss: 1.3514950275421143. Training Accuracy: 56.32022471910113.%\n",
            "Iteration: 900. Loss: 1.5765291452407837. Training Accuracy: 56.57602663706992.%\n",
            "Iteration: 1000. Loss: 1.61845862865448. Training Accuracy: 56.36863136863137.%\n",
            "Iteration: 0. Loss: 1.5878278017044067. Validation Accuracy: 37.5.%\n",
            "Iteration: 100. Loss: 1.1832841634750366. Validation Accuracy: 45.42079207920792.%\n",
            "Epoch 1 \t Training Loss: 1.0152313237947024 \t Training Accuracy: 56.3436329588015 \t Validation Loss: 1.222007146348124 \t Validation Accuracy: 48.3197093551317\n",
            "Accuracy increased(39.782016--->48.319709) \t Saving The Model\n",
            "Iteration: 0. Loss: 0.9975786209106445. Training Accuracy: 62.5.%\n",
            "Iteration: 100. Loss: 0.6548017859458923. Training Accuracy: 64.60396039603961.%\n",
            "Iteration: 200. Loss: 0.8191956877708435. Training Accuracy: 64.36567164179104.%\n",
            "Iteration: 300. Loss: 0.873004138469696. Training Accuracy: 66.2375415282392.%\n",
            "Iteration: 400. Loss: 1.0456739664077759. Training Accuracy: 66.30299251870325.%\n",
            "Iteration: 500. Loss: 1.328627109527588. Training Accuracy: 66.66666666666667.%\n",
            "Iteration: 600. Loss: 1.241058111190796. Training Accuracy: 64.51747088186356.%\n",
            "Iteration: 700. Loss: 1.3757466077804565. Training Accuracy: 63.62339514978602.%\n",
            "Iteration: 800. Loss: 1.3263769149780273. Training Accuracy: 63.45193508114856.%\n",
            "Iteration: 900. Loss: 1.254717230796814. Training Accuracy: 63.73473917869035.%\n",
            "Iteration: 1000. Loss: 1.1811847686767578. Training Accuracy: 63.773726273726275.%\n",
            "Iteration: 0. Loss: 1.5549366474151611. Validation Accuracy: 37.5.%\n",
            "Iteration: 100. Loss: 1.3792728185653687. Validation Accuracy: 48.886138613861384.%\n",
            "Epoch 2 \t Training Loss: 0.9028170748652143 \t Training Accuracy: 63.40121722846442 \t Validation Loss: 1.1802143499903057 \t Validation Accuracy: 50.22706630336058\n",
            "Accuracy increased(48.319709--->50.227066) \t Saving The Model\n",
            "Iteration: 0. Loss: 0.753885805606842. Training Accuracy: 75.0.%\n",
            "Iteration: 100. Loss: 0.5039533972740173. Training Accuracy: 69.05940594059406.%\n",
            "Iteration: 200. Loss: 0.5125755667686462. Training Accuracy: 70.33582089552239.%\n",
            "Iteration: 300. Loss: 0.6348552703857422. Training Accuracy: 71.63621262458472.%\n",
            "Iteration: 400. Loss: 0.5657378435134888. Training Accuracy: 72.0074812967581.%\n",
            "Iteration: 500. Loss: 1.1987040042877197. Training Accuracy: 72.67964071856288.%\n",
            "Iteration: 600. Loss: 1.2260267734527588. Training Accuracy: 70.34109816971714.%\n",
            "Iteration: 700. Loss: 1.0064446926116943. Training Accuracy: 70.0962910128388.%\n",
            "Iteration: 800. Loss: 1.4159722328186035. Training Accuracy: 69.89700374531836.%\n",
            "Iteration: 900. Loss: 1.0089956521987915. Training Accuracy: 70.1581576026637.%\n",
            "Iteration: 1000. Loss: 1.1227772235870361. Training Accuracy: 70.41708291708292.%\n",
            "Iteration: 0. Loss: 1.4642940759658813. Validation Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 1.335555076599121. Validation Accuracy: 50.99009900990099.%\n",
            "Epoch 3 \t Training Loss: 0.7763171305928784 \t Training Accuracy: 70.30664794007491 \t Validation Loss: 1.2635822663272636 \t Validation Accuracy: 50.22706630336058\n",
            "Iteration: 0. Loss: 0.7470769286155701. Training Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 0.4922840893268585. Training Accuracy: 75.61881188118812.%\n",
            "Iteration: 200. Loss: 0.49353936314582825. Training Accuracy: 77.42537313432835.%\n",
            "Iteration: 300. Loss: 0.7994412183761597. Training Accuracy: 77.49169435215947.%\n",
            "Iteration: 400. Loss: 0.48655572533607483. Training Accuracy: 78.83416458852868.%\n",
            "Iteration: 500. Loss: 0.536527156829834. Training Accuracy: 79.14171656686626.%\n",
            "Iteration: 600. Loss: 1.062627911567688. Training Accuracy: 76.74708818635607.%\n",
            "Iteration: 700. Loss: 0.6848746538162231. Training Accuracy: 76.33737517831669.%\n",
            "Iteration: 800. Loss: 1.3946219682693481. Training Accuracy: 76.02996254681648.%\n",
            "Iteration: 900. Loss: 0.38977035880088806. Training Accuracy: 76.19311875693674.%\n",
            "Iteration: 1000. Loss: 0.9470024108886719. Training Accuracy: 76.36113886113885.%\n",
            "Iteration: 0. Loss: 1.7182672023773193. Validation Accuracy: 25.0.%\n",
            "Iteration: 100. Loss: 2.032838821411133. Validation Accuracy: 49.62871287128713.%\n",
            "Epoch 4 \t Training Loss: 0.6705413272374132 \t Training Accuracy: 76.12359550561797 \t Validation Loss: 1.4248021748186885 \t Validation Accuracy: 48.59218891916439\n",
            "train took 4338.849sec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Training finished!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load best model\n",
        "model.load_state_dict(torch.load('./mymodel.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa10w5EVttD5",
        "outputId": "9a52f985-5727-4587-92c2-c8c9dcb78974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ROBERTAClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (d1): Dropout(p=0.3, inplace=False)\n",
              "  (l1): Linear(in_features=768, out_features=64, bias=True)\n",
              "  (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  (d2): Dropout(p=0.3, inplace=False)\n",
              "  (l2): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "PrXR5bHkfv8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@timebudget\n",
        "def test(model):\n",
        "\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (ids, attention_mask, labels) in enumerate(testing_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            ids = ids.cuda()\n",
        "            attention_mask = attention_mask.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        output = model.forward(ids,attention_mask=attention_mask)\n",
        "\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100.00 * correct / total\n",
        "\n",
        "        y_test.extend(labels.tolist())\n",
        "        y_pred.extend(predicted.tolist())\n",
        "\n",
        "        if i%100 == 0:      \n",
        "            print('Iteration: {}. Accuracy: {}%'.format(i, accuracy))\n",
        "\n",
        "\n",
        "    accuracy = 100.00 * correct / total\n",
        "    print('Final Accuracy: ', accuracy)\n",
        "    print('F1 score macro: ', f1_score(y_test, y_pred, average='macro'))\n",
        "    print('F1 score micro: ', f1_score(y_test, y_pred, average='micro'))"
      ],
      "metadata": {
        "id": "e_HAScACtXOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "test(model)"
      ],
      "metadata": {
        "id": "QrdWIfJDvQEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1bd3ec1-3f7f-4005-9400-d478ae108f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0. Accuracy: 37.5%\n",
            "Iteration: 100. Accuracy: 50.742574257425744%\n",
            "Iteration: 200. Accuracy: 51.92786069651741%\n",
            "Final Accuracy:  51.90045248868778\n",
            "F1 score macro:  0.5021061884643802\n",
            "F1 score micro:  0.5190045248868779\n",
            "test took 69.511sec\n"
          ]
        }
      ]
    }
  ]
}