{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82238d01f6c448e4bb587960f39f1723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33566efc1cf04610b3ac10d53c9b7dd3",
              "IPY_MODEL_fd7ea3ed4a684bc99b276349169e8c07",
              "IPY_MODEL_eb4aec36fcfd4d399ff3b2ef0ac527d2"
            ],
            "layout": "IPY_MODEL_7fe590c7b33a4db0976c62dc8d28864c"
          }
        },
        "33566efc1cf04610b3ac10d53c9b7dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea76dbc85f64663b9de5186ee9905ae",
            "placeholder": "​",
            "style": "IPY_MODEL_631695e030944160bbfebaaa192b41e8",
            "value": "100%"
          }
        },
        "fd7ea3ed4a684bc99b276349169e8c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd8febfe697b430e9970bbee229a46b1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12c4754853294ae1a4b66856be640917",
            "value": 5
          }
        },
        "eb4aec36fcfd4d399ff3b2ef0ac527d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a81a5ec252f747bcbcdb4e5d3fe9f74c",
            "placeholder": "​",
            "style": "IPY_MODEL_2537956ee5824bd98b0408f8a51a9c8b",
            "value": " 5/5 [1:12:18&lt;00:00, 867.22s/it]"
          }
        },
        "7fe590c7b33a4db0976c62dc8d28864c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea76dbc85f64663b9de5186ee9905ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631695e030944160bbfebaaa192b41e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd8febfe697b430e9970bbee229a46b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c4754853294ae1a4b66856be640917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a81a5ec252f747bcbcdb4e5d3fe9f74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2537956ee5824bd98b0408f8a51a9c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mining of large datasets - Project**\n",
        "## Deep Learning approach using RoBERTa to classify the SST-5 dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "ESYom5NrsWY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install required packages (if needed)\n",
        "! pip install transformers\n",
        "! pip install imbalanced-learn\n",
        "! pip install timebudget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY1VAxsrtj5e",
        "outputId": "c4dd3bda-4f64-4083-db24-bc311ca41e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timebudget in /usr/local/lib/python3.7/dist-packages (0.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "WCD9r7U-ayU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBHBH_88sAbp"
      },
      "outputs": [],
      "source": [
        "#Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
        "\n",
        "from timebudget import timebudget\n",
        "timebudget.report_atexit()  # Generate report when the program exits\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets (train, validation and testing)\n",
        "\n",
        "We have included a zip file containing the datasets."
      ],
      "metadata": {
        "id": "OB03mvw7a8Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load training, validation and testing datasets\n",
        "train_dataset = pd.read_csv('./train.txt', sep=\"\\t\", header=None, names=[\"label\", \"data\"])\n",
        "validation_dataset = pd.read_csv('./dev.txt', sep=\"\\t\", header=None, names=[\"label\", \"data\"])\n",
        "test_dataset = pd.read_csv('./test.txt', sep=\"\\t\", header=None, names=[\"label\", \"data\"])"
      ],
      "metadata": {
        "id": "ODnchrohsGda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore distribution of datasets\n",
        "\n",
        "fig, ax = plt.subplots(3, figsize=(5,10))\n",
        "fig.suptitle('Distribution of datasets')\n",
        "\n",
        "#Training data\n",
        "ax[0] = train_dataset['label'].value_counts(sort=False).plot(kind='barh', ax=ax[0])\n",
        "ax[0].set_xlabel('Number of Samples (Training)')\n",
        "ax[0].set_ylabel('Label')\n",
        "\n",
        "for i, v in enumerate(train_dataset['label'].value_counts(sort=False)):\n",
        "    ax[0].text(v + 3, i + .25, str(v), fontweight='bold')\n",
        "\n",
        "# #Validation data\n",
        "ax[1] = validation_dataset['label'].value_counts(sort=False).plot(kind='barh', ax=ax[1])\n",
        "ax[1].set_xlabel('Number of Samples (Validation)')\n",
        "ax[1].set_ylabel('Label')\n",
        "\n",
        "for i, v in enumerate(validation_dataset['label'].value_counts(sort=False)):\n",
        "    ax[1].text(v + 3, i + .25, str(v), fontweight='bold')\n",
        "\n",
        "# #Testing data\n",
        "ax[2] = train_dataset['label'].value_counts(sort=False).plot(kind='barh', ax=ax[2])\n",
        "ax[2].set_xlabel('Number of Samples (Testing)')\n",
        "ax[2].set_ylabel('Label')\n",
        "\n",
        "for i, v in enumerate(test_dataset['label'].value_counts(sort=False)):\n",
        "    ax[2].text(v + 3, i + .25, str(v), fontweight='bold')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "uzcMxNR6f8dD",
        "outputId": "bfcc5001-a0e7-4c47-f91b-704957a10911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x720 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balancing datasets\n",
        "\n",
        "To deal with unbalanced data we will oversample and undersample the datasets"
      ],
      "metadata": {
        "id": "wN5SVLKcckyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Oversampling minority classes\n",
        "c0 = train_dataset[train_dataset['label'] == 1]\n",
        "c1 = train_dataset[train_dataset['label'] == 2]\n",
        "c2 = train_dataset[train_dataset['label'] == 3]\n",
        "c3 = train_dataset[train_dataset['label'] == 4]\n",
        "c4 = train_dataset[train_dataset['label'] == 5]\n",
        "\n",
        "max_count = train_dataset.label.value_counts().max()\n",
        "\n",
        "over_c0 = c0.sample(max_count, replace='True')\n",
        "over_c1 = c1.sample(max_count, replace='True')\n",
        "over_c2 = c2.sample(max_count, replace='True')\n",
        "over_c4 = c4.sample(max_count, replace='True')\n",
        "\n",
        "oversampled_train_dataset = pd.concat([over_c0,over_c1, over_c2, c3, over_c4], axis=0)\n",
        "\n",
        "#Undersampling majority classes\n",
        "min_count = train_dataset.label.value_counts().min()\n",
        "under_c1 = c1.sample(min_count)\n",
        "under_c2 = c2.sample(min_count)\n",
        "under_c3 = c3.sample(min_count)\n",
        "under_c4 = c4.sample(min_count)\n",
        "\n",
        "undersampled_train_dataset = pd.concat([c0,under_c1, under_c2, under_c3, under_c4], axis=0)\n",
        "\n",
        "print('Oversampled dataset: \\n', oversampled_train_dataset.label.value_counts())\n",
        "\n",
        "print('Undersampled dataset: \\n', undersampled_train_dataset.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij9pZUBocpuk",
        "outputId": "7f2909ea-9387-4ca1-9ac3-e03887560212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oversampled dataset: \n",
            " 1    2322\n",
            "2    2322\n",
            "3    2322\n",
            "4    2322\n",
            "5    2322\n",
            "Name: label, dtype: int64\n",
            "Undersampled dataset: \n",
            " 1    1092\n",
            "2    1092\n",
            "3    1092\n",
            "4    1092\n",
            "5    1092\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define architecture of RoBERTa model\n",
        "\n",
        "class ROBERTAClassifier(torch.nn.Module):\n",
        "    def __init__(self, n_classes, dropout_rate=0.3):\n",
        "        super(ROBERTAClassifier, self).__init__()\n",
        "        \n",
        "        # config = RobertaConfig.from_pretrained('roberta-base')\n",
        "        # config.num_labels = n_classes\n",
        "        # self.roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)\n",
        "\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l1 = torch.nn.Linear(768, 64)\n",
        "        self.bn1 = torch.nn.LayerNorm(64)\n",
        "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l2 = torch.nn.Linear(64, n_classes)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "\n",
        "        # x = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0]\n",
        "\n",
        "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "\n",
        "        x = self.d1(x)\n",
        "        x = self.l1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.nn.Tanh()(x)\n",
        "        x = self.d2(x)\n",
        "\n",
        "        x = self.l2(x)\n",
        "        # x = F.softmax(self.l2(x), dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WLpwcWP_waNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the number of classes\n",
        "n_classes = train_dataset['label'].nunique()\n",
        "print('N classes: ', n_classes)\n",
        "\n",
        "model = ROBERTAClassifier(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGK2aZL2wiYm",
        "outputId": "7fd0c169-8b64-403e-9a2a-63e3ccd7ed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N classes:  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "id": "i9fYTGaSwlkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features(review, zero_pad = False, max_seq_length = 512):\n",
        "    \n",
        "    enc_text = tokenizer.encode_plus(text=review, add_special_tokens=True, max_length=max_seq_length, padding='max_length', truncation=True)\n",
        "    return enc_text"
      ],
      "metadata": {
        "id": "GQPFvPTQ9PIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_review = train_dataset.loc[0]['data']\n",
        "print(example_review)\n",
        "enc_example = prepare_features(example_review)\n",
        "print(enc_example)\n",
        "print(len(enc_example['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdhcORzd98B7",
        "outputId": "777801c5-efb5-4a7b-ffe2-d74a46834e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
            "{'input_ids': [0, 133, 2751, 16, 19083, 7, 28, 5, 733, 620, 9348, 128, 29, 92, 45518, 38650, 12801, 8, 14, 37, 128, 29, 164, 7, 146, 10, 17158, 190, 2388, 87, 11816, 28797, 2156, 5363, 12, 11428, 5247, 3415, 8234, 1794, 50, 5031, 1608, 9487, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Class to prepare X and Y data\n",
        "class Format_Data(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        review = self.data['data'].iloc[index]\n",
        "\n",
        "        X = prepare_features(review)\n",
        "\n",
        "        #Transform current classes [1,2,3,4,5] to [0,1,2,3,4]\n",
        "        y = self.data['label'].iloc[index] - 1\n",
        "        \n",
        "        return np.array(X['input_ids']), np.array(X['attention_mask']), np.array(y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "28XzPYZU-buk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = Format_Data(train_dataset)\n",
        "# oversampled_training_set = Format_Data(oversampled_train_dataset)\n",
        "# undersampled_training_set = Format_Data(undersampled_train_dataset)\n",
        "\n",
        "validation_set = Format_Data(validation_dataset)\n"
      ],
      "metadata": {
        "id": "IObL842O_nY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_set = Format_Data(test_dataset)"
      ],
      "metadata": {
        "id": "qFpwg3eAeniX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataloaders Parameters\n",
        "params = {'batch_size': 8}\n"
      ],
      "metadata": {
        "id": "PFPcIAYyADs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training using undersampled/oversampled/original dataset"
      ],
      "metadata": {
        "id": "JhedR1xqgiGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# u_training_loader = DataLoader(undersampled_training_set, **params)\n",
        "# o_training_loader = DataLoader(oversampled_training_set, **params)\n",
        "training_loader = DataLoader(training_set, **params)\n",
        "validation_loader = DataLoader(validation_set, **params)\n"
      ],
      "metadata": {
        "id": "Meg0zQmpeqjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_loader = DataLoader(testing_set, **params)"
      ],
      "metadata": {
        "id": "ockteNPMesvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.AdamW(params=model.parameters(), betas=(0.9, 0.98), lr=learning_rate)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is AVAILABLE!🤘🙌💪\")\n",
        "    model = model.cuda()"
      ],
      "metadata": {
        "id": "4eXvG6IaAKr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d74b8cd-93f2-4be1-e376-4f74cb6c9d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is AVAILABLE!🤘🙌💪\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "@timebudget\n",
        "def train(model, epochs, training_loader_):\n",
        "  best_accuracy = 0.0 \n",
        "  max_epochs = epochs\n",
        "  for epoch in tqdm_notebook(range(max_epochs)):\n",
        "\n",
        "      train_loss = 0.0\n",
        "      model.train()\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for i, (ids, attention_mask, labels) in enumerate(training_loader_):\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          if torch.cuda.is_available():\n",
        "              ids = ids.cuda()\n",
        "              attention_mask = attention_mask.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "          output = model.forward(ids, attention_mask=attention_mask)\n",
        "\n",
        "          loss = loss_function(output, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item()\n",
        "\n",
        "          #Output acc every 100\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          accuracy = 100.00 * correct / total\n",
        "\n",
        "          if i%100 == 0:\n",
        "              print('Iteration: {}. Loss: {}. Training Accuracy: {}.%'.format(i, loss.item(), accuracy))\n",
        "\n",
        "      #Calculate training accuracy and loss\n",
        "      final_t_accuracy = 100.00 * correct / total\n",
        "      avg_t_loss = train_loss / len(training_loader_)\n",
        "        \n",
        "      #Validation loop\n",
        "      valid_loss = 0.0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "          model.eval()\n",
        "          for i, (ids, attention_mask, labels) in enumerate(validation_loader):\n",
        "\n",
        "              if torch.cuda.is_available():\n",
        "                  ids = ids.cuda()\n",
        "                  attention_mask = attention_mask.cuda()\n",
        "                  labels = labels.cuda()\n",
        "          \n",
        "              output = model.forward(ids, attention_mask=attention_mask)\n",
        "              loss = loss_function(output, labels)\n",
        "              valid_loss += loss.item()\n",
        "\n",
        "              _, predicted = torch.max(output, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              accuracy = 100.00 * correct / total\n",
        "\n",
        "              if i%100 == 0:\n",
        "                  print('Iteration: {}. Loss: {}. Validation Accuracy: {}.%'.format(i, loss.item(), accuracy))\n",
        "\n",
        "      #Calculate validation accuracy and loss\n",
        "      final_v_accuracy = 100.00 * correct / total\n",
        "      avg_v_loss = valid_loss / len(validation_loader)\n",
        "\n",
        "      #Report results per epoch\n",
        "      print(f'Epoch {epoch} \\t Training Loss: {avg_t_loss} \\t Training Accuracy: {final_t_accuracy} \\t Validation Loss: {avg_v_loss} \\t Validation Accuracy: {final_v_accuracy}')\n",
        "\n",
        "      # Save the model if the accuracy is the best \n",
        "      if final_v_accuracy > best_accuracy: \n",
        "            print(f'Accuracy increased({best_accuracy:.6f}--->{final_v_accuracy:.6f}) \\t Saving The Model')\n",
        "            best_accuracy = final_v_accuracy\n",
        "            torch.save(model.state_dict(), './mymodel.pt')                    \n",
        "  \n",
        "  return \"Training finished!\""
      ],
      "metadata": {
        "id": "jTIUuNsZAwS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, 5, training_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "82238d01f6c448e4bb587960f39f1723",
            "33566efc1cf04610b3ac10d53c9b7dd3",
            "fd7ea3ed4a684bc99b276349169e8c07",
            "eb4aec36fcfd4d399ff3b2ef0ac527d2",
            "7fe590c7b33a4db0976c62dc8d28864c",
            "6ea76dbc85f64663b9de5186ee9905ae",
            "631695e030944160bbfebaaa192b41e8",
            "cd8febfe697b430e9970bbee229a46b1",
            "12c4754853294ae1a4b66856be640917",
            "a81a5ec252f747bcbcdb4e5d3fe9f74c",
            "2537956ee5824bd98b0408f8a51a9c8b"
          ]
        },
        "id": "ku2uAUAgGamV",
        "outputId": "77e2cfcd-1522-48b3-e59f-c882c8b2805c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  import sys\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82238d01f6c448e4bb587960f39f1723",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0. Loss: 1.9123878479003906. Training Accuracy: 0.0.%\n",
            "Iteration: 100. Loss: 1.4801982641220093. Training Accuracy: 42.82178217821782.%\n",
            "Iteration: 200. Loss: 1.0363661050796509. Training Accuracy: 45.646766169154226.%\n",
            "Iteration: 300. Loss: 0.8117481470108032. Training Accuracy: 47.79900332225914.%\n",
            "Iteration: 400. Loss: 1.1208134889602661. Training Accuracy: 49.781795511221944.%\n",
            "Iteration: 500. Loss: 1.4582126140594482. Training Accuracy: 50.424151696606785.%\n",
            "Iteration: 600. Loss: 1.137970209121704. Training Accuracy: 48.48169717138103.%\n",
            "Iteration: 700. Loss: 1.7825311422348022. Training Accuracy: 48.44864479315264.%\n",
            "Iteration: 800. Loss: 1.1688129901885986. Training Accuracy: 48.36142322097378.%\n",
            "Iteration: 900. Loss: 1.3552838563919067. Training Accuracy: 48.46004439511654.%\n",
            "Iteration: 1000. Loss: 1.305487036705017. Training Accuracy: 48.57642357642358.%\n",
            "Iteration: 0. Loss: 1.6790359020233154. Validation Accuracy: 25.0.%\n",
            "Iteration: 100. Loss: 1.0806810855865479. Validation Accuracy: 38.242574257425744.%\n",
            "Epoch 0 \t Training Loss: 1.1728694087891989 \t Training Accuracy: 48.46676029962547 \t Validation Loss: 1.3268241173979165 \t Validation Accuracy: 39.782016348773844\n",
            "Accuracy increased(0.000000--->39.782016) \t Saving The Model\n",
            "Iteration: 0. Loss: 1.4137310981750488. Training Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 0.9568563103675842. Training Accuracy: 58.415841584158414.%\n",
            "Iteration: 200. Loss: 0.8020365834236145. Training Accuracy: 57.77363184079602.%\n",
            "Iteration: 300. Loss: 0.9872041344642639. Training Accuracy: 58.43023255813954.%\n",
            "Iteration: 400. Loss: 0.8540629744529724. Training Accuracy: 59.03990024937656.%\n",
            "Iteration: 500. Loss: 1.2937661409378052. Training Accuracy: 59.231536926147704.%\n",
            "Iteration: 600. Loss: 1.2098586559295654. Training Accuracy: 57.009151414309486.%\n",
            "Iteration: 700. Loss: 1.4137415885925293. Training Accuracy: 56.65121255349501.%\n",
            "Iteration: 800. Loss: 1.3514950275421143. Training Accuracy: 56.32022471910113.%\n",
            "Iteration: 900. Loss: 1.5765291452407837. Training Accuracy: 56.57602663706992.%\n",
            "Iteration: 1000. Loss: 1.61845862865448. Training Accuracy: 56.36863136863137.%\n",
            "Iteration: 0. Loss: 1.5878278017044067. Validation Accuracy: 37.5.%\n",
            "Iteration: 100. Loss: 1.1832841634750366. Validation Accuracy: 45.42079207920792.%\n",
            "Epoch 1 \t Training Loss: 1.0152313237947024 \t Training Accuracy: 56.3436329588015 \t Validation Loss: 1.222007146348124 \t Validation Accuracy: 48.3197093551317\n",
            "Accuracy increased(39.782016--->48.319709) \t Saving The Model\n",
            "Iteration: 0. Loss: 0.9975786209106445. Training Accuracy: 62.5.%\n",
            "Iteration: 100. Loss: 0.6548017859458923. Training Accuracy: 64.60396039603961.%\n",
            "Iteration: 200. Loss: 0.8191956877708435. Training Accuracy: 64.36567164179104.%\n",
            "Iteration: 300. Loss: 0.873004138469696. Training Accuracy: 66.2375415282392.%\n",
            "Iteration: 400. Loss: 1.0456739664077759. Training Accuracy: 66.30299251870325.%\n",
            "Iteration: 500. Loss: 1.328627109527588. Training Accuracy: 66.66666666666667.%\n",
            "Iteration: 600. Loss: 1.241058111190796. Training Accuracy: 64.51747088186356.%\n",
            "Iteration: 700. Loss: 1.3757466077804565. Training Accuracy: 63.62339514978602.%\n",
            "Iteration: 800. Loss: 1.3263769149780273. Training Accuracy: 63.45193508114856.%\n",
            "Iteration: 900. Loss: 1.254717230796814. Training Accuracy: 63.73473917869035.%\n",
            "Iteration: 1000. Loss: 1.1811847686767578. Training Accuracy: 63.773726273726275.%\n",
            "Iteration: 0. Loss: 1.5549366474151611. Validation Accuracy: 37.5.%\n",
            "Iteration: 100. Loss: 1.3792728185653687. Validation Accuracy: 48.886138613861384.%\n",
            "Epoch 2 \t Training Loss: 0.9028170748652143 \t Training Accuracy: 63.40121722846442 \t Validation Loss: 1.1802143499903057 \t Validation Accuracy: 50.22706630336058\n",
            "Accuracy increased(48.319709--->50.227066) \t Saving The Model\n",
            "Iteration: 0. Loss: 0.753885805606842. Training Accuracy: 75.0.%\n",
            "Iteration: 100. Loss: 0.5039533972740173. Training Accuracy: 69.05940594059406.%\n",
            "Iteration: 200. Loss: 0.5125755667686462. Training Accuracy: 70.33582089552239.%\n",
            "Iteration: 300. Loss: 0.6348552703857422. Training Accuracy: 71.63621262458472.%\n",
            "Iteration: 400. Loss: 0.5657378435134888. Training Accuracy: 72.0074812967581.%\n",
            "Iteration: 500. Loss: 1.1987040042877197. Training Accuracy: 72.67964071856288.%\n",
            "Iteration: 600. Loss: 1.2260267734527588. Training Accuracy: 70.34109816971714.%\n",
            "Iteration: 700. Loss: 1.0064446926116943. Training Accuracy: 70.0962910128388.%\n",
            "Iteration: 800. Loss: 1.4159722328186035. Training Accuracy: 69.89700374531836.%\n",
            "Iteration: 900. Loss: 1.0089956521987915. Training Accuracy: 70.1581576026637.%\n",
            "Iteration: 1000. Loss: 1.1227772235870361. Training Accuracy: 70.41708291708292.%\n",
            "Iteration: 0. Loss: 1.4642940759658813. Validation Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 1.335555076599121. Validation Accuracy: 50.99009900990099.%\n",
            "Epoch 3 \t Training Loss: 0.7763171305928784 \t Training Accuracy: 70.30664794007491 \t Validation Loss: 1.2635822663272636 \t Validation Accuracy: 50.22706630336058\n",
            "Iteration: 0. Loss: 0.7470769286155701. Training Accuracy: 50.0.%\n",
            "Iteration: 100. Loss: 0.4922840893268585. Training Accuracy: 75.61881188118812.%\n",
            "Iteration: 200. Loss: 0.49353936314582825. Training Accuracy: 77.42537313432835.%\n",
            "Iteration: 300. Loss: 0.7994412183761597. Training Accuracy: 77.49169435215947.%\n",
            "Iteration: 400. Loss: 0.48655572533607483. Training Accuracy: 78.83416458852868.%\n",
            "Iteration: 500. Loss: 0.536527156829834. Training Accuracy: 79.14171656686626.%\n",
            "Iteration: 600. Loss: 1.062627911567688. Training Accuracy: 76.74708818635607.%\n",
            "Iteration: 700. Loss: 0.6848746538162231. Training Accuracy: 76.33737517831669.%\n",
            "Iteration: 800. Loss: 1.3946219682693481. Training Accuracy: 76.02996254681648.%\n",
            "Iteration: 900. Loss: 0.38977035880088806. Training Accuracy: 76.19311875693674.%\n",
            "Iteration: 1000. Loss: 0.9470024108886719. Training Accuracy: 76.36113886113885.%\n",
            "Iteration: 0. Loss: 1.7182672023773193. Validation Accuracy: 25.0.%\n",
            "Iteration: 100. Loss: 2.032838821411133. Validation Accuracy: 49.62871287128713.%\n",
            "Epoch 4 \t Training Loss: 0.6705413272374132 \t Training Accuracy: 76.12359550561797 \t Validation Loss: 1.4248021748186885 \t Validation Accuracy: 48.59218891916439\n",
            "train took 4338.849sec\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Training finished!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load best model\n",
        "model.load_state_dict(torch.load('./mymodel.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa10w5EVttD5",
        "outputId": "9a52f985-5727-4587-92c2-c8c9dcb78974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ROBERTAClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (d1): Dropout(p=0.3, inplace=False)\n",
              "  (l1): Linear(in_features=768, out_features=64, bias=True)\n",
              "  (bn1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  (d2): Dropout(p=0.3, inplace=False)\n",
              "  (l2): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "PrXR5bHkfv8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@timebudget\n",
        "def test(model):\n",
        "\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (ids, attention_mask, labels) in enumerate(testing_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            ids = ids.cuda()\n",
        "            attention_mask = attention_mask.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        output = model.forward(ids,attention_mask=attention_mask)\n",
        "\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100.00 * correct / total\n",
        "\n",
        "        y_test.extend(labels.tolist())\n",
        "        y_pred.extend(predicted.tolist())\n",
        "\n",
        "        if i%100 == 0:      \n",
        "            print('Iteration: {}. Accuracy: {}%'.format(i, accuracy))\n",
        "\n",
        "\n",
        "    accuracy = 100.00 * correct / total\n",
        "    print('Final Accuracy: ', accuracy)\n",
        "    print('F1 score macro: ', f1_score(y_test, y_pred, average='macro'))\n",
        "    print('F1 score micro: ', f1_score(y_test, y_pred, average='micro'))"
      ],
      "metadata": {
        "id": "e_HAScACtXOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "test(model)"
      ],
      "metadata": {
        "id": "QrdWIfJDvQEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1bd3ec1-3f7f-4005-9400-d478ae108f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0. Accuracy: 37.5%\n",
            "Iteration: 100. Accuracy: 50.742574257425744%\n",
            "Iteration: 200. Accuracy: 51.92786069651741%\n",
            "Final Accuracy:  51.90045248868778\n",
            "F1 score macro:  0.5021061884643802\n",
            "F1 score micro:  0.5190045248868779\n",
            "test took 69.511sec\n"
          ]
        }
      ]
    }
  ]
}